#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ‰¹é‡ç‰ˆï¼šç”¨ ATR æŠŠâ€œæ³¢åŠ¨â€é‡åŒ–ï¼ˆç»™è¾¹ç•Œå®šå°ºåº¦ï¼‰ï¼Œä¸ºå¤šæ ‡çš„ events ç”Ÿæˆ TP/SLã€‚

äº®ç‚¹ï¼š
- å…¼å®¹å•æ–‡ä»¶ & ç›®å½•æ‰¹é‡ä¸¤ç§ç”¨æ³•
- è‡ªåŠ¨è¯†åˆ« K çº¿åˆ—åï¼ˆOpen/High/Low/Closeï¼‰ä¸æ—¶é—´åˆ—ï¼ˆtimestamp/datetime/...ï¼‰
- events çš„ t_entry æ”¯æŒâ€œæ—¶é—´æˆ³â€æˆ–â€œKçº¿è¡Œå·â€ï¼›entry_price ç¼ºå¤±ä¼šè‡ªåŠ¨è¡¥
- é»˜è®¤æŒ‰æ–‡ä»¶åè‡ªåŠ¨é…å¯¹ï¼ˆAAPL_1d.parquet â†” AAPL_events.csvï¼‰
- å¯é€‰è‡ªå®šä¹‰æ­£åˆ™ --regex æ¥æŠ½å–â€œæ ‡çš„ä»£ç â€ï¼ˆå‘½åä¸ç»Ÿä¸€ä¹Ÿèƒ½æå®šï¼‰
- å¹¶è¡Œå¤„ç† --jobs N
- ä¸ºæ¯ä¸ªæ ‡çš„è¾“å‡ºå„è‡ª CSVï¼Œä¸”å¯ä¸€é”®åˆå¹¶ä¸ºä¸€ä¸ªæ€»è¡¨ --merge_all all.csv

ç”¨æ³•ç¤ºä¾‹ï¼š
1) å¤„ç†å•ä¸ªæ ‡çš„ï¼ˆå®Œå…¨å…¼å®¹æ—§è„šæœ¬ï¼‰
   python events_make_barriers_batch.py \
       --ohlcv data/AAPL_1d.parquet \
       --events events/AAPL_events.csv \
       --out out/AAPL_events_with_barriers.csv \
       --entry_when next_open --k 2.0 --m 1.0 --atr_window 20

2) ä¸€æ¬¡æ€§å¤„ç† 20 ä¸ªæ ‡çš„ï¼ˆç›®å½•æ‰¹é‡ï¼‰
   python events_make_barriers_batch.py \
       --ohlcv data/kline_dir \
       --events data/events_dir \
       --out_dir out/batch \
       --entry_when next_open --k 2.0 --m 1.0 --atr_window 20 \
       --merge_all out/batch/all_events_with_barriers.csv \
       --jobs 4

3) å‘½åä¸ç»Ÿä¸€ï¼Ÿç”¨æ­£åˆ™æŒ‡å®šâ€œä»£ç â€æŠ½å–è§„åˆ™ï¼ˆæå–å‘½åä¸­çš„ (?P<sym>...)ï¼‰
   python events_make_barriers_batch.py \
       --ohlcv data/kline_dir --events data/events_dir --out_dir out/batch \
       --regex "(?P<sym>[A-Z]{1,5}(?:\.[A-Z]{2})?)"  # ä¾‹å¦‚ AAPLã€TSLAã€HK.00700

å¤‡æ³¨ï¼š
- ATR å‰ n æ ¹ä¸º NaN å±æ­£å¸¸ï¼›è¿™äº›æ—¶åˆ»çš„äº‹ä»¶ä¼šè¢«ä¸¢å¼ƒï¼ˆæ— è¶³å¤Ÿå†å²æ³¢åŠ¨ï¼‰
- direction: 1=åšå¤šï¼Œ-1=åšç©ºï¼›è‹¥ç¼ºå¤±é»˜è®¤æŒ‰ 1 å¤„ç†
- entry_when: next_open=ä»¥ä¸‹ä¸€æ ¹å¼€ç›˜ä»·å…¥åœºï¼›this_close=ä»¥å½“å‰æ ¹æ”¶ç›˜ä»·å…¥åœº
"""

from __future__ import annotations
import argparse
import re
from pathlib import Path
from typing import Dict, Iterable, List, Optional, Tuple
import pandas as pd
import numpy as np
from concurrent.futures import ThreadPoolExecutor, as_completed

# ====================== å·¥å…·ï¼šåˆ—åæ¸…æ´—ä¸åŒ¹é… ======================

def _clean(s: str) -> str:
    return s.lower().replace(" ", "").replace("_", "")

def _pick_col(cols: Iterable[str], options: Iterable[str]) -> Optional[str]:
    options = set(options)
    for c in cols:
        if _clean(c) in options:
            return c
    return None

# ====================== 1) è¯»å– K çº¿ï¼ˆè‡ªåŠ¨è¯†åˆ«æ—¶é—´åˆ—/ç´¢å¼• & OHLC å˜ä½“ï¼‰ ======================

def load_ohlcv_flexible(path: str) -> pd.DataFrame:
    p = Path(path)
    if not p.exists():
        raise FileNotFoundError(f"æœªæ‰¾åˆ°Kçº¿æ–‡ä»¶: {p}")
    df = pd.read_parquet(p) if p.suffix.lower() == ".parquet" else pd.read_csv(p)

    ts_col = _pick_col(df.columns, {"timestamp","time","datetime","date"})
    if ts_col is not None:
        ts = pd.to_datetime(df[ts_col], utc=True, errors="coerce")
    else:
        if pd.api.types.is_datetime64_any_dtype(df.index):
            ts = pd.to_datetime(df.index, utc=True)
        else:
            idx_col = _pick_col(df.columns, {"index"})
            if idx_col is not None:
                ts = pd.to_datetime(df[idx_col], utc=True, errors="coerce")
            else:
                raise ValueError("æ— æ³•åœ¨ K çº¿é‡Œæ‰¾åˆ°æ—¶é—´åˆ—ï¼ˆtimestamp/time/datetime/dateï¼‰æˆ–æ—¶é—´ç´¢å¼•ã€‚")

    if ts.isna().all():
        raise ValueError("K çº¿æ—¶é—´åˆ—è§£æå¤±è´¥ï¼ˆå…¨æ˜¯ NaNï¼‰")

    cols = list(df.columns)
    c_open  = _pick_col(cols, {"open","o"})
    c_high  = _pick_col(cols, {"high","h"})
    c_low   = _pick_col(cols, {"low","l"})
    c_close = _pick_col(cols, {"close","c"})
    if c_close is None:
        c_close = _pick_col(cols, {"adjclose","adjustedclose","adjcloseprice"})

    need_map: Dict[str, str] = {}
    if not c_open or not c_high or not c_low or not c_close:
        missing = [k for k,v in [("open",c_open),("high",c_high),("low",c_low),("close",c_close)] if not v]
        raise ValueError(f"Kçº¿ç¼ºå°‘å¿…è¦åˆ—ï¼ˆæ¥å—å¤§å°å†™/å˜ä½“ï¼‰ï¼š{missing}")

    need_map["open"]  = c_open
    need_map["high"]  = c_high
    need_map["low"]   = c_low
    need_map["close"] = c_close

    out = pd.DataFrame({
        "timestamp": ts,
        "open":  pd.to_numeric(df[need_map["open"]],  errors="coerce"),
        "high":  pd.to_numeric(df[need_map["high"]],  errors="coerce"),
        "low":   pd.to_numeric(df[need_map["low"]],   errors="coerce"),
        "close": pd.to_numeric(df[need_map["close"]], errors="coerce"),
    })
    out = out.dropna(subset=["timestamp","open","high","low","close"])\
             .sort_values("timestamp")\
             .drop_duplicates("timestamp")\
             .set_index("timestamp")
    if len(out) == 0:
        raise ValueError("K çº¿æ¸…æ´—åä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ•°æ®å†…å®¹ã€‚")
    return out

# ====================== 2) è®¡ç®— ATR ======================

def compute_atr(df: pd.DataFrame, n: int = 20, method: str = "rma") -> pd.Series:
    prev_close = df["close"].shift(1)
    tr = pd.concat([
        df["high"] - df["low"],
        (df["high"] - prev_close).abs(),
        (df["low"] - prev_close).abs()
    ], axis=1).max(axis=1)
    if method == "sma":
        return tr.rolling(window=n, min_periods=n).mean()
    else:  # rmaï¼ˆRMA=EMAçš„ç‰¹æ®Šå‚æ•°ï¼‰
        return tr.ewm(alpha=1/n, adjust=False, min_periods=n).mean()

# ====================== 3) è¯»å– eventsï¼ˆè‡ªåŠ¨åˆ†è¾¨ t_entry æ˜¯â€œæ—¶é—´æˆ³â€è¿˜æ˜¯â€œè¡Œå·â€ï¼‰ ======================

def load_events_auto(path: str, df: pd.DataFrame, entry_when: str) -> pd.DataFrame:
    ev = pd.read_csv(path)

    if "t_entry" not in ev.columns:
        for alt in ["entry_ts","entry_time","entry_datetime","entry_loc","entry_idx","entry_i"]:
            if alt in ev.columns:
                ev = ev.rename(columns={alt:"t_entry"})
                break
    if "t_entry" not in ev.columns:
        raise ValueError("events ä¸­æ‰¾ä¸åˆ° t_entryï¼ˆæˆ–åˆ«å entry_ts/entry_time/entry_loc ç­‰ï¼‰")

    if "direction" not in ev.columns:
        ev["direction"] = 1
    ev["direction"] = ev["direction"].astype(int)

    if "entry_price" in ev.columns:
        ev["entry_price"] = pd.to_numeric(ev["entry_price"], errors="coerce")
    else:
        ev["entry_price"] = np.nan

    is_numeric = pd.api.types.is_integer_dtype(ev["t_entry"]) or pd.api.types.is_float_dtype(ev["t_entry"])
    if is_numeric:
        ev["t_entry"] = ev["t_entry"].astype(int)
        ev["mode"] = "positional"
    else:
        ev["t_entry"] = pd.to_datetime(ev["t_entry"], utc=True, errors="coerce")
        if ev["t_entry"].isna().any():
            raise ValueError("events é‡Œæœ‰æ— æ³•è§£æçš„æ—¶é—´å€¼ï¼ˆt_entryï¼‰")
        ev["mode"] = "timestamp"

    if ev["entry_price"].isna().any():
        if ev["mode"].iloc[0] == "positional":
            price_series = df["open"] if entry_when == "next_open" else df["close"]
            ev.loc[ev["entry_price"].isna(), "entry_price"] = ev.loc[ev["entry_price"].isna(), "t_entry"].map(
                lambda i: float(price_series.iloc[int(i)]) if 0 <= int(i) < len(df) else np.nan
            )
        else:
            price_series = df["open"] if entry_when == "next_open" else df["close"]
            ev = ev.set_index("t_entry").join(price_series.rename("_price_snap"), how="left")
            ev["entry_price"] = ev["entry_price"].fillna(ev["_price_snap"])
            ev = ev.drop(columns=["_price_snap"]).reset_index()

    ev = ev.dropna(subset=["entry_price"]).reset_index(drop=True)
    return ev

# ====================== 4) ç”Ÿæˆ TP/SL ======================

def add_barriers_auto(df: pd.DataFrame, ev: pd.DataFrame, atr: pd.Series,
                      k: float, m: float, entry_when: str) -> pd.DataFrame:
    atr_for_entry = atr.shift(1) if entry_when == "next_open" else atr

    if ev["mode"].iloc[0] == "positional":
        ev["atr_entry"] = ev["t_entry"].map(lambda i: float(atr_for_entry.iloc[int(i)]) if 0 <= int(i) < len(df) else np.nan)
    else:
        ev = ev.set_index("t_entry").join(atr_for_entry.rename("atr_entry"), how="left").reset_index()

    ev = ev.dropna(subset=["atr_entry"]).reset_index(drop=True)

    is_long  = ev["direction"] == 1
    is_short = ev["direction"] == -1

    ev.loc[is_long,  "tp"] = ev.loc[is_long,  "entry_price"] + k * ev.loc[is_long,  "atr_entry"]
    ev.loc[is_long,  "sl"] = ev.loc[is_long,  "entry_price"] - m * ev.loc[is_long,  "atr_entry"]

    ev.loc[is_short, "tp"] = ev.loc[is_short, "entry_price"] - k * ev.loc[is_short, "atr_entry"]
    ev.loc[is_short, "sl"] = ev.loc[is_short, "entry_price"] + m * ev.loc[is_short, "atr_entry"]

    ev["check_ok"] = True
    ev.loc[is_long,  "check_ok"] &= (ev.loc[is_long,  "tp"] > ev.loc[is_long,  "entry_price"]) & (ev.loc[is_long,  "sl"] < ev.loc[is_long,  "entry_price"])
    ev.loc[is_short, "check_ok"] &= (ev.loc[is_short, "tp"] < ev.loc[is_short, "entry_price"]) & (ev.loc[is_short, "sl"] > ev.loc[is_short, "entry_price"])

    return ev

# ====================== 5) æ–‡ä»¶é…å¯¹ï¼ˆè‡ªåŠ¨ or æ­£åˆ™ï¼‰ ======================

def _list_ohlcv(ohlcv_input: str) -> List[Path]:
    p = Path(ohlcv_input)
    if p.is_file():
        return [p]
    if p.is_dir():
        files: List[Path] = []
        files.extend(sorted(p.glob("*.parquet")))
        files.extend(sorted(p.glob("*.csv")))
        return files
    raise FileNotFoundError(f"æœªæ‰¾åˆ°è·¯å¾„: {p}")


def _list_events(events_input: str) -> List[Path]:
    p = Path(events_input)
    if p.is_file():
        return [p]
    if p.is_dir():
        return sorted(p.glob("*.csv"))
    raise FileNotFoundError(f"æœªæ‰¾åˆ°è·¯å¾„: {p}")


def _extract_sym_from_name(path: Path, regex: Optional[str]) -> str:
    name = path.name
    if regex:
        m = re.search(regex, name)
        if m:
            if "sym" in m.groupdict():
                return str(m.group("sym")).lower()
            if m.groups():
                return str(m.group(1)).lower()
    # fallbackï¼šå–æ–‡ä»¶åé‡Œæœ€é•¿çš„å­—æ¯æ•°å­—ç‰‡æ®µä½œä¸ºâ€œä»£ç â€
    stem = path.stem#è·å–æ–‡ä»¶çš„ä¸»å¹²åï¼ˆå³å»æ‰è·¯å¾„å’Œæ‰©å±•ååçš„éƒ¨åˆ†ï¼‰ã€‚ä¾‹å¦‚ï¼šPath("/data/AAPL_20230101.csv").stem å¾—åˆ° "AAPL_20230101"ã€‚
    tokens = re.findall(r"[A-Za-z0-9\.]+", stem)
    blacklist = {"events","event","ohlcv","kline","data","day","1d","d","15y","y","parquet","csv","bars","quotes",}
    tokens = [t for t in tokens if t.lower() not in blacklist]
    if not tokens:
        return stem.lower()
    tokens.sort(key=lambda t: (-len(t), t))
    return tokens[0].lower()


def pair_files(ohlcv_list: List[Path], events_list: List[Path], regex: Optional[str]) -> List[Tuple[str, Path, Path]]:
    o_map: Dict[str, Path] = {}
    for f in ohlcv_list:
        key = _extract_sym_from_name(f, regex)
        if key in o_map:#è¿™æ˜¯ä¸€ä¸ªå†²çªå¤„ç†æœºåˆ¶ã€‚å¦‚æœå½“å‰æå–å‡ºçš„ä»£ç  key å·²ç»å­˜åœ¨äº o_map å­—å…¸ä¸­äº†ï¼Œè¯´æ˜æˆ‘ä»¬é‡åˆ°äº†åŒä¸€ä¸ªè‚¡ç¥¨æœ‰å¤šä¸ªOHLCVæ–‡ä»¶çš„æƒ…å†µã€‚
            # å°½é‡æ›´åå¥½ parquetï¼ˆæ›´å¿«æ›´ç¨³ï¼‰
            prefer = f if f.suffix.lower()==".parquet" else o_map[key]
            o_map[key] = prefer
        else:
            o_map[key] = f

    e_map: Dict[str, Path] = {}
    for f in events_list:
        key = _extract_sym_from_name(f, regex)
        if key in e_map:
            # åŒä¸€ä¸ªä»£ç å‡ºç°å¤šä¸ª eventsï¼šä¿ç•™â€œæœ€è¿‘ä¿®æ”¹â€çš„é‚£ä¸ª
            prefer = f if f.stat().st_mtime >= e_map[key].stat().st_mtime else e_map[key]
            #f.stat().st_mtimeï¼š è¿™é‡Œç”¨åˆ°äº† .stat() æ–¹æ³•ï¼Œå®ƒå¯ä»¥è·å–æ–‡ä»¶çš„å…ƒä¿¡æ¯ï¼ˆæˆ–ç§° metadataï¼‰ã€‚
            # .st_mtime æ˜¯å…ƒä¿¡æ¯ä¸­çš„ä¸€é¡¹ï¼Œä»£è¡¨æ–‡ä»¶æœ€åçš„ä¿®æ”¹æ—¶é—´ï¼ˆmodification timeï¼‰ï¼Œå®ƒæ˜¯ä¸€ä¸ªæ—¶é—´æˆ³æ•°å­—ã€‚
            e_map[key] = prefer
        else:
            e_map[key] = f

    keys = sorted(set(o_map) & set(e_map))
    pairs = [(k, o_map[k], e_map[k]) for k in keys]

    # å‘å‡ºæç¤ºï¼šå“ªäº› unmatched
    miss_ohlcv = sorted(set(e_map) - set(o_map))
    miss_events = sorted(set(o_map) - set(e_map))
    if miss_ohlcv:
        print(f"âš ï¸ è¿™äº› events æ²¡æ‰¾åˆ°å¯¹åº”çš„ K çº¿ï¼ˆæŒ‰ä»£ç æŠ½å–é€»è¾‘ï¼‰ï¼š{miss_ohlcv}")
    if miss_events:
        print(f"âš ï¸ è¿™äº› K çº¿æ²¡æ‰¾åˆ°å¯¹åº”çš„ eventsï¼ˆæŒ‰ä»£ç æŠ½å–é€»è¾‘ï¼‰ï¼š{miss_events}")

    return pairs

# ====================== 6) å•æ ‡çš„æ‰§è¡Œ & æ‰¹é‡é©±åŠ¨ ======================

def run_single(ohlcv_path: Path, events_path: Path, out_csv: Path,
               atr_window: int, atr_method: str, entry_when: str, k: float, m: float,
               symbol: Optional[str]=None) -> Tuple[str, Optional[pd.DataFrame], Optional[str]]:
    """è¿”å› (symbol, df_out or None, err_msg or None)"""
    sym = symbol or _extract_sym_from_name(ohlcv_path, None)
    try:
        print(f"ğŸ“¦ è¯»å– K çº¿: {ohlcv_path}")
        df = load_ohlcv_flexible(str(ohlcv_path))
        print(f"   æ¡æ•°: {len(df)}  æ—¶é—´èŒƒå›´(UTC): {df.index.min()} ~ {df.index.max()}")

        print(f"ğŸ“¦ è¯»å– events: {events_path}")
        ev = load_events_auto(str(events_path), df, entry_when)
        print(f"   äº‹ä»¶æ¡æ•°(åŸå§‹ä¸”å·²è¡¥ä»·): {len(ev)}  æ¨¡å¼: {ev['mode'].iloc[0]}")

        print(f"ğŸ§® è®¡ç®— ATR(n={atr_window}, method={atr_method}) ...")
        atr = compute_atr(df, n=atr_window, method=atr_method)
        print(f"   ATRå¯ç”¨æ¯”ä¾‹: {atr.notna().mean():.2%}ï¼ˆå‰ {atr_window} æ ¹ NaN æ­£å¸¸ï¼‰")

        print(f"ğŸ¯ ç”Ÿæˆ TP/SLï¼ˆå…¥åœº={entry_when}ï¼Œk={k}ï¼Œm={m}ï¼‰ ...")
        out = add_barriers_auto(df, ev, atr, k=k, m=m, entry_when=entry_when)

        # è‹¥å·²æœ‰ symbol åˆ—åˆ™è¦†ç›–ï¼›æ²¡æœ‰åˆ™æ’å…¥åˆ°é¦–åˆ—
        if "symbol" in out.columns:
            out["symbol"] = sym
        else:
            out.insert(0, "symbol", sym)

        out["src_ohlcv"] = ohlcv_path.name
        out["src_events"] = events_path.name

        # ç»Ÿä¸€æŠŠ symbol æ”¾åˆ°æœ€å‰ï¼ˆå¦‚æœæ˜¯è¦†ç›–çš„æƒ…å†µï¼‰
        cols_order = ["symbol"] + [c for c in out.columns if c != "symbol"]
        out = out[cols_order]

        # å†™ç›˜ï¼šç¡®ä¿ç›®å½•å­˜åœ¨ï¼ˆæ— è®º out_csv æ˜¯ str è¿˜æ˜¯ Pathï¼‰
        out_path = out_csv if isinstance(out_csv, Path) else Path(out_csv)
        out_path.parent.mkdir(parents=True, exist_ok=True)
        out.to_csv(out_path, index=False, encoding="utf-8-sig")
        print(f"âœ… å·²å¯¼å‡º: {out_path}  æ¡æ•°: {len(out)}")
        return sym, out, None
    except Exception as e:
        return sym, None, f"{type(e).__name__}: {e}"


def run_batch(ohlcv_input: str, events_input: str, out_dir: str,
              atr_window: int, atr_method: str, entry_when: str, k: float, m: float,
              regex: Optional[str], jobs: int, merge_all: Optional[str]) -> None:
    ohlcv_list = _list_ohlcv(ohlcv_input)
    events_list = _list_events(events_input)

    # è‹¥ä¸¤è¾¹éƒ½æ˜¯å•æ–‡ä»¶ï¼Œèµ°å•æ ‡çš„ï¼›å¦åˆ™æ‰¹é‡
    if len(ohlcv_list) == 1 and len(events_list) == 1:
        out_csv = Path(out_dir)
        if out_csv.is_dir():
            sym = _extract_sym_from_name(ohlcv_list[0], regex)
            out_csv = out_csv / f"{sym}_events_with_barriers.csv"
        run_single(ohlcv_list[0], events_list[0], out_csv, atr_window, atr_method, entry_when, k, m)
        return

    # æ‰¹é‡ï¼šé…å¯¹
    pairs = pair_files(ohlcv_list, events_list, regex)
    if not pairs:
        raise SystemExit("æœªé…å¯¹åˆ°ä»»ä½• (ohlcv, events)ã€‚è¯·æ£€æŸ¥å‘½åæˆ–ä½¿ç”¨ --regexã€‚")

    out_dir_p = Path(out_dir)
    out_dir_p.mkdir(parents=True, exist_ok=True)

    results: List[pd.DataFrame] = []

    def _task(pair: Tuple[str, Path, Path]):
        sym, o_path, e_path = pair
        out_csv = out_dir_p / f"{sym}_events_with_barriers.csv"
        return run_single(o_path, e_path, out_csv, atr_window, atr_method, entry_when, k, m, symbol=sym)

    if jobs and jobs > 1:
        with ThreadPoolExecutor(max_workers=jobs) as ex:
            futs = {ex.submit(_task, p): p[0] for p in pairs}
            for fut in as_completed(futs):
                sym = futs[fut]
                s, df_out, err = fut.result()
                if err:
                    print(f"âŒ {sym}: {err}")
                elif df_out is not None:
                    results.append(df_out)
    else:
        for p in pairs:
            sym, df_out, err = _task(p)
            if err:
                print(f"âŒ {sym}: {err}")
            elif df_out is not None:
                results.append(df_out)

    if merge_all and results:
        all_df = pd.concat(results, ignore_index=True)
        out_all = Path(merge_all)
        out_all.parent.mkdir(parents=True, exist_ok=True)
        all_df.to_csv(out_all, index=False, encoding="utf-8-sig")
        print(f"ğŸ“š æ±‡æ€»å·²å¯¼å‡º: {out_all}  æ¡æ•°: {len(all_df)}")

# ====================== 7) CLI ======================

def main():
    ap = argparse.ArgumentParser(description="æ‰¹é‡ç”¨ ATR ä¸º events ç”Ÿæˆ TP/SLï¼ˆè‡ªåŠ¨é…å¯¹/å¯æ­£åˆ™/å¯å¹¶è¡Œï¼‰")
    ap.add_argument("--ohlcv", required=True, help="Kçº¿æ–‡ä»¶æˆ–ç›®å½•ï¼ˆ.parquet/.csvï¼‰")
    ap.add_argument("--events", required=True, help="events.csv æ–‡ä»¶æˆ–ç›®å½•ï¼ˆ.csvï¼‰")

    # å•æ–‡ä»¶æ¨¡å¼ä¸‹ï¼š--out æ˜¯è¾“å‡ºæ–‡ä»¶ï¼›ç›®å½•æ‰¹é‡ä¸‹ï¼š--out_dir æ˜¯è¾“å‡ºç›®å½•
    ap.add_argument("--out", help="å•æ–‡ä»¶æ¨¡å¼ä¸‹è¾“å‡º CSV è·¯å¾„ï¼›è‹¥æ˜¯ç›®å½•åˆ™è‡ªåŠ¨å‘½å")
    ap.add_argument("--out_dir", help="æ‰¹é‡æ¨¡å¼ä¸‹è¾“å‡ºç›®å½•")

    ap.add_argument("--atr_window", type=int, default=20)
    ap.add_argument("--atr_method", choices=["rma","sma"], default="rma")
    ap.add_argument("--entry_when", choices=["next_open","this_close"], default="next_open")
    ap.add_argument("--k", type=float, default=2.0)
    ap.add_argument("--m", type=float, default=1.0)

    ap.add_argument("--regex", help="æ–‡ä»¶åä¸­æŠ½å–æ ‡çš„ä»£ç ç”¨çš„æ­£åˆ™ï¼›å¯åŒ…å«å‘½ååˆ†ç»„ (?P<sym>...)")
    ap.add_argument("--jobs", type=int, default=0, help="å¹¶è¡Œçº¿ç¨‹æ•°ï¼ˆ>1 å¯ç”¨å¹¶è¡Œï¼‰")
    ap.add_argument("--merge_all", help="åˆå¹¶å…¨éƒ¨æ ‡çš„è¾“å‡ºä¸ºä¸€ä¸ª CSV çš„è·¯å¾„ï¼ˆå¯é€‰ï¼‰")

    args = ap.parse_args()

    # åˆ¤å®šè¿è¡Œæ¨¡å¼
    ohlcv_is_file = Path(args.ohlcv).is_file()
    events_is_file = Path(args.events).is_file()

    if ohlcv_is_file and events_is_file:
        if not args.out and not args.out_dir:
            raise SystemExit("å•æ–‡ä»¶æ¨¡å¼éœ€è¦ --outï¼ˆæˆ–ç»™ --out_dir ä¸€ä¸ªç›®å½•ï¼Œæˆ‘ä¼šè‡ªåŠ¨å‘½åï¼‰ã€‚")
        out_target = args.out or args.out_dir
        run_batch(args.ohlcv, args.events, out_target, args.atr_window, args.atr_method,
                  args.entry_when, args.k, args.m, args.regex, jobs=0, merge_all=None)
    else:
        out_dir = args.out_dir or args.out
        if not out_dir:
            raise SystemExit("ç›®å½•æ‰¹é‡æ¨¡å¼éœ€è¦æä¾› --out_dirï¼ˆæˆ–ç”¨ --out æŒ‡å‘ä¸€ä¸ªç›®å½•ï¼‰ã€‚")
        run_batch(args.ohlcv, args.events, out_dir, args.atr_window, args.atr_method,
                  args.entry_when, args.k, args.m, args.regex, args.jobs, args.merge_all)


if __name__ == "__main__":
    main()
#python .\events_make_barriers.py `--ohlcv "D:\chan\chan.py\data\stooq\1d_15y" `--events "D:\chan\chan.py\events_outputs" `--out_dir "D:\chan\chan.py\events_outputs\barriers" `--entry_when next_open --k 2.0 --m 1.0 --atr_window 20 `--merge_all "D:\chan\chan.py\events_outputs\barriers\all_events_with_barriers.csv" `--jobs 4
