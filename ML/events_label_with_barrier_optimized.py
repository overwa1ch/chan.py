#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# events_label_with_right_barrier_batch.py â€”â€” ä¼˜åŒ–ç‰ˆ
# å˜æ›´ç‚¹ï¼ˆå¯¹æ¯”åŸç‰ˆ + èåˆ step4 ç‰¹æ€§ï¼‰ï¼š
# 1) å…¥åœºå®šä½æ›´å¥å£®ï¼šè‹¥ç»™çš„æ˜¯æ—¶é—´æˆ³ï¼Œå…ˆåšæ—¶åŒºå¯¹é½ï¼›ç²¾ç¡®åŒ¹é…å¤±è´¥æ—¶å¯å–â€œæœ€è¿‘ä¸€æ ¹â€ï¼ˆå¯è®¾å®¹å·® --nearest_tolï¼‰ã€‚
# 2) å…¥åœºä»·ç­–ç•¥å¯é€‰ï¼š--entry_price_policy æ”¯æŒ 'same_open'ï¼ˆåŒæ ¹å¼€ç›˜ï¼‰ä¸ 'next_open'ï¼ˆåä¸€æ ¹å¼€ç›˜ï¼Œé»˜è®¤ï¼‰ã€‚
#    è‹¥ events å†…å·²æœ‰ entry_price åˆ—ï¼Œåˆ™ä¼˜å…ˆç”Ÿæ•ˆï¼›å¦åˆ™æŒ‰ç­–ç•¥å›é€€ï¼›è‹¥ç¼º open åˆ—åˆ™å›é€€åˆ° closeã€‚
# 3) è¾“å‡ºæ–°å¢ t_entryï¼ˆå…¥åœºæ—¶é—´æˆ³ï¼‰ï¼Œå¹¶æ²¿ç”¨ exit_timeã€retã€exit_reason ç­‰ï¼›ä¿ç•™ bars_heldï¼ŒåŒæ—¶æ–°å¢ holding_barsï¼ˆåŒä¹‰ï¼‰ã€‚
# 4) å…¶ä½™é€»è¾‘ï¼ˆTP/SL ä¼˜å…ˆçº§ã€è´¹ç”¨ã€å³è¾¹ç•ŒæŒ‰ H_bars/H_timeï¼‰ä¿æŒå…¼å®¹ï¼›CLI å¢åŠ ä¸Šè¿°æ–°å‚æ•°ã€‚
#
# ç”¨æ³•ç¤ºä¾‹ï¼š
"""
python events_label_with_barrier_optimized.py `
--ohlcv "D:\chan\chan.py\data\stooq\1d_15y" `
--ewb "D:\chan\chan.py\events_outputs\barriers" `
--out_dir "D:/chan/chan.py/events_outputs/labels" `
--H_bars 10 `
--fee 0.0005 `
--tie sl_first `
--entry_price_policy next_open `
--nearest_tol 5min `
--jobs 4 `
--merge_all "D:/chan/chan.py/events_outputs/labels/all_events_labeled.csv" 
  """


from __future__ import annotations
import argparse
import re
from pathlib import Path
from typing import Dict, Iterable, List, Optional, Tuple, Union
import numpy as np
import pandas as pd
from concurrent.futures import ThreadPoolExecutor, as_completed

# ====================== å·¥å…·ï¼šåˆ—åæ¸…æ´—ä¸åŒ¹é… ======================

def _clean(s: str) -> str:
    return s.lower().replace(" ", "").replace("_", "")

def _pick_col(cols: Iterable[str], options: Iterable[str]) -> Optional[str]:
    options = set(options)
    for c in cols:
        if _clean(c) in options:
            return c
    return None

# ====================== 1) è¯»å– K çº¿ï¼ˆè‡ªåŠ¨è¯†åˆ«æ—¶é—´åˆ—/ç´¢å¼• & OHLC å˜ä½“ï¼‰ ======================

def load_ohlcv_flexible(path: str) -> pd.DataFrame:
    p = Path(path)
    if not p.exists():
        raise FileNotFoundError(f"æœªæ‰¾åˆ°Kçº¿æ–‡ä»¶: {p}")
    df = pd.read_parquet(p) if p.suffix.lower() == ".parquet" else pd.read_csv(p)

    # æ—¶é—´åˆ—æˆ–ç´¢å¼• -> DatetimeIndexï¼ˆå°½é‡ UTC-awareï¼Œè‹¥å·²æœ‰ tz åˆ™ä¿ç•™ï¼‰
    ts_col = _pick_col(df.columns, {"timestamp","time","datetime","date"})
    if ts_col is not None:
        ts = pd.to_datetime(df[ts_col], utc=True, errors="coerce")  # ç»Ÿä¸€è½¬ä¸º UTC-aware
    else:
        if pd.api.types.is_datetime64_any_dtype(df.index):
            # å°è¯•ä¿ç•™åŸç´¢å¼•æ—¶åŒºï¼ˆè‹¥æœ‰çš„è¯ï¼‰ï¼›è‹¥æ—  tzï¼Œåˆ™ä»ä¸º naive
            ts = pd.to_datetime(df.index, utc=False, errors="coerce")
        else:
            idx_col = _pick_col(df.columns, {"index"})
            if idx_col is not None:
                ts = pd.to_datetime(df[idx_col], utc=True, errors="coerce")
            else:
                raise ValueError("æ— æ³•åœ¨ K çº¿é‡Œæ‰¾åˆ°æ—¶é—´åˆ—ï¼ˆtimestamp/time/datetime/dateï¼‰æˆ–æ—¶é—´ç´¢å¼•ã€‚")

    if ts.isna().all():
        raise ValueError("K çº¿æ—¶é—´åˆ—è§£æå¤±è´¥ï¼ˆå…¨æ˜¯ NaNï¼‰")

    cols = list(df.columns)
    c_open  = _pick_col(cols, {"open","o"})
    c_high  = _pick_col(cols, {"high","h"})
    c_low   = _pick_col(cols, {"low","l"})
    c_close = _pick_col(cols, {"close","c"})
    missing = [name for name, v in [("open",c_open),("high",c_high),("low",c_low),("close",c_close)] if not v]
    if missing:
        raise ValueError(f"Kçº¿ç¼ºå°‘å¿…è¦åˆ—ï¼ˆæ¥å—å¤§å°å†™/å˜ä½“ï¼‰ï¼š{missing}")

    out = pd.DataFrame({
        "timestamp": ts,
        "open":  pd.to_numeric(df[c_open],  errors="coerce"),
        "high":  pd.to_numeric(df[c_high],  errors="coerce"),
        "low":   pd.to_numeric(df[c_low],   errors="coerce"),
        "close": pd.to_numeric(df[c_close], errors="coerce"),
    })
    out = out.dropna(subset=["timestamp","open","high","low","close"]) \
             .sort_values("timestamp") \
             .drop_duplicates("timestamp") \
             .set_index("timestamp")

    if len(out) == 0:
        raise ValueError("K çº¿æ¸…æ´—åä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ•°æ®å†…å®¹ã€‚")
    return out

# ====================== å³è¾¹ç•Œä¸æ ‡ç­¾é€»è¾‘ ======================

def _to_timedelta(x) -> Optional[pd.Timedelta]:
    if x is None or (isinstance(x, float) and np.isnan(x)):
        return None
    if isinstance(x, pd.Timedelta):
        return x
    import datetime as _dt
    if isinstance(x, _dt.timedelta):
        return pd.to_timedelta(x)
    if isinstance(x, np.timedelta64):
        return pd.to_timedelta(x)
    if isinstance(x, (str, int, float)):
        # çº¯æ•°å­—è§†ä¸ºâ€œå¤©â€ï¼›å­—ç¬¦ä¸²å¦‚ '90min','2H','3D' ç›´æ¥äº¤ç»™ to_timedelta
        return pd.to_timedelta(x, unit="D") if isinstance(x, (int, float)) else pd.to_timedelta(x)
    raise TypeError(f"H_time ç±»å‹ä¸æ”¯æŒ: {type(x)}")

def right_barrier_loc(df: pd.DataFrame, entry_loc: int, H_bars: Optional[int]=None, H_time: Optional[Union[str,int,float,pd.Timedelta]]=None) -> int:
    n = len(df)
    if not (0 <= int(entry_loc) < n):
        raise IndexError(f"entry_loc è¶Šç•Œ: {entry_loc}, æ•°æ®è¡Œæ•°: {n}")
    if (H_bars is None) == (H_time is None):
        raise ValueError("H_BARS ä¸ H_TIME å¿…é¡»äºŒé€‰ä¸€ï¼ˆä¸€ä¸ªæœ‰å€¼ã€å¦ä¸€ä¸ªä¸º Noneï¼‰ã€‚")
    if H_bars is not None:
        Hb = int(H_bars)
        if Hb < 0:
            raise ValueError("H_BARS ä¸èƒ½ä¸ºè´Ÿæ•°")
        return min(int(entry_loc) + Hb, n - 1)

    Ht = _to_timedelta(H_time)
    idx = df.index
    if not isinstance(idx, pd.DatetimeIndex):
        try:
            idx = pd.to_datetime(idx)
        except Exception as e:
            raise ValueError("ä½¿ç”¨ H_TIME æ—¶éœ€è¦ DatetimeIndexï¼ˆæˆ–å¯è¢« to_datetime è½¬æ¢ï¼‰ã€‚") from e
    if not idx.is_monotonic_increasing:
        raise ValueError("ç´¢å¼•éœ€è¦æŒ‰æ—¶é—´å‡åºã€‚è¯·å…ˆ sort_index().")
    entry_ts = idx[int(entry_loc)]
    deadline = entry_ts + Ht
    loc = int(np.searchsorted(idx.values, deadline, side="right") - 1)
    loc = max(loc, int(entry_loc))
    loc = min(loc, n - 1)
    return loc

def label_one_given(df: pd.DataFrame, entry_loc: int, entry_price: float, tp: float, sl: float, direction: int,
                    H_bars=None, H_time=None, fee_pct: float=0.0005, tie: str="sl_first"):
    end_loc = right_barrier_loc(df, entry_loc, H_bars=H_bars, H_time=H_time)
    cost = 2 * float(fee_pct)
    for loc in range(int(entry_loc) + 1, int(end_loc) + 1):
        hi = float(df.iloc[loc]['high']); lo = float(df.iloc[loc]['low'])
        if direction == 1:
            hit_tp = hi >= tp; hit_sl = lo <= sl
        else:
            hit_tp = lo <= tp; hit_sl = hi >= sl
        if hit_tp and hit_sl:
            if tie == "sl_first":
                exit_price = sl; gross = direction * (exit_price / entry_price - 1.0)
                return 0, gross - cost, loc, "SL&TP_samebar->SL", loc - int(entry_loc)
            else:
                exit_price = tp; gross = direction * (exit_price / entry_price - 1.0)
                return 1, gross - cost, loc, "SL&TP_samebar->TP", loc - int(entry_loc)
        if hit_tp:
            exit_price = tp; gross = direction * (exit_price / entry_price - 1.0)
            return 1, gross - cost, loc, "TP", loc - int(entry_loc)
        if hit_sl:
            exit_price = sl; gross = direction * (exit_price / entry_price - 1.0)
            return 0, gross - cost, loc, "SL", loc - int(entry_loc)
    exit_loc = int(end_loc)
    exit_price = float(df.iloc[exit_loc]['close'])
    gross = direction * (exit_price / entry_price - 1.0)
    y = 1 if (direction==1 and exit_price >= tp) or (direction==-1 and exit_price <= tp) else 0
    return y, gross - cost, exit_loc, "TIMEOUT", exit_loc - int(entry_loc)

# ====================== è§£æ entry_loc / entry_price ======================

def _pick_price_from_row_or_policy(df: pd.DataFrame, row: pd.Series, loc: int, entry_price_policy: str) -> float:
    # æ˜¾å¼ entry_price ä¼˜å…ˆ
    if "entry_price" in row and pd.notna(row["entry_price"]):
        return float(row["entry_price"])

    cols = set(c.lower() for c in df.columns)
    col_open  = "open"  if "open"  in cols else next((c for c in df.columns if c.lower()=="open"),  None)
    col_close = "close" if "close" in cols else next((c for c in df.columns if c.lower()=="close"), None)
    if not col_open and not col_close:
        raise KeyError("Kçº¿æ•°æ®ç¼ºå°‘ open/close åˆ—ï¼Œæ— æ³•æ¨å¯¼å…¥åœºä»·")

    if entry_price_policy == "next_open":
        if loc + 1 < len(df) and col_open:
            return float(df.iloc[loc+1][col_open])
        # åä¸€æ ¹ä¸å­˜åœ¨æˆ–ç¼º open â†’ å›é€€
        fallback_col = col_open or col_close
        return float(df.iloc[loc][fallback_col])
    else:  # same_open
        if col_open:
            return float(df.iloc[loc][col_open])
        return float(df.iloc[loc][col_close])

def _align_ts_to_index(entry_dt: pd.Timestamp, idx: pd.DatetimeIndex, nearest_tol: Optional[pd.Timedelta]) -> Optional[int]:
    """æŠŠ entry_dt æ˜ å°„åˆ° idx çš„ ilocã€‚ä¼˜å…ˆç²¾ç¡®åŒ¹é…ï¼›ä¸è¡Œåˆ™æœ€è¿‘ï¼ˆå¯è®¾ç½®å®¹å·®ï¼‰ã€‚"""
    # ä¸ç´¢å¼•å¯¹é½æ—¶åŒº
    if getattr(idx, "tz", None) is None:
        entry_dt = entry_dt.tz_localize(None)  # ç´¢å¼•æ˜¯ naive
    else:
        entry_dt = entry_dt.tz_convert(idx.tz) # ç´¢å¼•æ˜¯ tz-aware

    # ç²¾ç¡®åŒ¹é…
    try:
        return int(idx.get_loc(entry_dt))
    except Exception:
        pass

    # æœ€è¿‘åŒ¹é…
    try:
        pos = int(idx.get_indexer([entry_dt], method="nearest")[0])
    except Exception:
        return None
    if pos == -1:
        return None
    if nearest_tol is not None:
        dt_near = idx[pos]
        try:
            if abs(dt_near - entry_dt) > nearest_tol:
                return None
        except Exception:
            # å‡å¦‚ä¸åŒ tz/ç±»å‹æ¯”è¾ƒå¤±è´¥ï¼Œå°±ç›´æ¥æ¥å—æœ€è¿‘
            pass
    return pos

def resolve_entry_loc(df: pd.DataFrame, row: pd.Series,
                      entry_price_policy: str = "next_open",
                      nearest_tol: Optional[pd.Timedelta] = None) -> Tuple[int, float]:
    """è¿”å› (iloc, entry_price)ï¼›æ”¯æŒæ•´æ•° iloc æˆ–æ—¶é—´æˆ³å…¥åœº."""
    # 1) ç›´æ¥æ•´æ•°è¡Œå·
    for key in ["t_entry_idx", "entry_idx", "entry_loc", "i_entry"]:
        if key in row and pd.notna(row[key]):
            loc = int(row[key])
            if not (0 <= loc < len(df)):
                raise ValueError(f"{key} è¶Šç•Œ: {loc}")
            price = _pick_price_from_row_or_policy(df, row, loc, entry_price_policy)
            return loc, price

    # 2) æ—¶é—´æˆ³
    for key in ["t_entry","entry_time","signal_time"]:
        if key in row and pd.notna(row[key]):
            ts = pd.to_datetime(row[key], utc=True, errors="coerce")  # å…ˆç»Ÿä¸€æˆ UTC-aware
            if pd.isna(ts):
                raise ValueError(f"æ— æ³•è§£æå…¥åœºæ—¶é—´: {row[key]}")
            idx = df.index if isinstance(df.index, pd.DatetimeIndex) else pd.to_datetime(df.index, errors="coerce", utc=False)
            loc = _align_ts_to_index(ts, idx, nearest_tol)
            if loc is None:
                raise KeyError(f"äº‹ä»¶æ—¶é—´ {ts} æ— æ³•åœ¨ K çº¿ç´¢å¼•ä¸­æ‰¾åˆ°åŒ¹é…ï¼ˆå«æœ€è¿‘é€»è¾‘ï¼‰ã€‚")
            price = _pick_price_from_row_or_policy(df, row, int(loc), entry_price_policy)
            return int(loc), price

    raise ValueError("äº‹ä»¶ç¼ºå°‘ t_entry_idx æˆ– t_entry/entry_time/signal_time")

# ====================== é…å¯¹å·¥å…· ======================

def _extract_sym_from_name(path: Path, regex: Optional[str]) -> str:
    name = path.name
    if regex:
        m = re.search(regex, name)
        if m:
            if "sym" in m.groupdict():
                return str(m.group("sym")).lower()
            if m.groups():
                return str(m.group(1)).lower()
    stem = path.stem
    tokens = re.findall(r"[A-Za-z0-9\.]+", stem)
    blacklist = {"events","event","ohlcv","kline","data","day","1d","d","15y","y","parquet","csv","bars","quotes","with","barriers"}
    tokens = [t for t in tokens if t.lower() not in blacklist]
    if not tokens:
        return stem.lower()
    tokens.sort(key=lambda t: (-len(t), t))
    return tokens[0].lower()

def list_ohlcv(ohlcv_input: str) -> List[Path]:
    p = Path(ohlcv_input)
    if p.is_file():
        return [p]
    if p.is_dir():
        files: List[Path] = []
        files.extend(sorted(p.glob("*.parquet")))
        files.extend(sorted(p.glob("*.csv")))
        return files
    raise FileNotFoundError(f"æœªæ‰¾åˆ°è·¯å¾„: {p}")

def list_ewb(ewb_input: str) -> Tuple[bool, List[Path]]:
    """è¿”å› (is_single_csv, æ–‡ä»¶åˆ—è¡¨)ã€‚å• CSV æ¨¡å¼ä¸‹åˆ—è¡¨åªå«è¯¥æ–‡ä»¶ã€‚"""
    p = Path(ewb_input)
    if p.is_file():
        return True, [p]
    if p.is_dir():
        return False, sorted(p.glob("*_events_with_barriers.csv"))
    raise FileNotFoundError(f"æœªæ‰¾åˆ°è·¯å¾„: {p}")

# ====================== ä¸»æµç¨‹ï¼šå•æ ‡çš„ä¸æ‰¹é‡ ======================

def run_one_symbol(sym: str, df: pd.DataFrame, ev: pd.DataFrame, out_csv: Path,
                   H_bars: Optional[int], H_time: Optional[str], fee_pct: float, tie: str,
                   entry_price_policy: str, nearest_tol: Optional[pd.Timedelta]) -> Tuple[str, Optional[pd.DataFrame], Optional[str]]:
    try:
        # ç»Ÿä¸€ direction / å¿…è¦åˆ—
        if "direction" not in ev.columns:
            ev["direction"] = 1
        ev["direction"] = ev["direction"].astype(int)

        out_rows = []
        for _, row in ev.iterrows():
            try:
                loc, price = resolve_entry_loc(df, row, entry_price_policy=entry_price_policy, nearest_tol=nearest_tol)
            except Exception:
                # å…¥åœºå®šä½å¤±è´¥ï¼šè·³è¿‡è¯¥æ¡
                continue
            direction = int(row.get("direction", 1))
            if pd.notna(row.get("tp")) and pd.notna(row.get("sl")):
                tp = float(row["tp"]); sl = float(row["sl"])
            else:
                # ä¿é™©ï¼šè‹¥ç¼ºå¤± tp/slï¼Œè·³è¿‡ï¼ˆä¹Ÿå¯åœ¨æ­¤æ·»åŠ  ATRÃ—å€æ•°çš„è‡ªåŠ¨ç”Ÿæˆï¼‰
                continue
            y, r, exit_loc, reason, bars = label_one_given(
                df, int(loc), float(price), tp, sl, direction,
                H_bars=H_bars, H_time=H_time, fee_pct=fee_pct, tie=tie
            )
            rec = dict(row)
            rec.update({
                "symbol": sym,
                "t_entry": df.index[int(loc)] if isinstance(df.index, pd.DatetimeIndex) else None,
                "t_entry_idx": int(loc),
                "entry_price": float(price),
                "y": int(y),
                "ret": float(r),
                "exit_idx": int(exit_loc),
                "exit_time": df.index[int(exit_loc)] if isinstance(df.index, pd.DatetimeIndex) else None,
                "exit_reason": reason,
                "bars_held": int(bars),
                "holding_bars": int(bars),
            })
            out_rows.append(rec)

        out = pd.DataFrame(out_rows)
        out_path = out_csv if isinstance(out_csv, Path) else Path(out_csv)
        out_path.parent.mkdir(parents=True, exist_ok=True)
        out.to_csv(out_path, index=False, encoding="utf-8-sig")
        print(f"âœ… å·²å¯¼å‡º: {out_path}  æ¡æ•°: {len(out)}")
        return sym, out, None
    except Exception as e:
        return sym, None, f"{type(e).__name__}: {e}"

def run_batch(ohlcv_input: str, ewb_input: str, out_dir: str,
              H_bars: Optional[int], H_time: Optional[str], fee_pct: float, tie: str,
              regex: Optional[str], jobs: int, merge_all: Optional[str],
              entry_price_policy: str, nearest_tol: Optional[pd.Timedelta]) -> None:
    ohlcv_list = list_ohlcv(ohlcv_input)
    is_single_csv, ewb_list = list_ewb(ewb_input)

    # å»ºç«‹ symbol -> Kçº¿æ–‡ä»¶ çš„æ˜ å°„
    sym2k: Dict[str, Path] = {}
    for f in ohlcv_list:
        k = _extract_sym_from_name(f, regex)
        sym2k[k] = f

    out_dir_p = Path(out_dir)
    out_dir_p.mkdir(parents=True, exist_ok=True)

    results: List[pd.DataFrame] = []

    if is_single_csv:
        # è¯»å–æ€»è¡¨ï¼ŒæŒ‰ symbol åˆ†ç»„
        big = pd.read_csv(ewb_list[0])
        if 'symbol' not in big.columns:
            raise ValueError("æ€»è¡¨ç¼ºå°‘ symbol åˆ—")
        # æ—¶é—´åˆ—è‹¥å­˜åœ¨ï¼Œè½¬æˆ UTCï¼Œé¿å… get_loc å¤±è´¥
        for col in ["t_entry","entry_time","signal_time"]:
            if col in big.columns:
                big[col] = pd.to_datetime(big[col], utc=True, errors="coerce")
        groups = big.groupby(big['symbol'].astype(str))

        def _task(sym: str, sub: pd.DataFrame):
            key = str(sym).lower()
            if key not in sym2k:
                print(f"âš ï¸ æ²¡æ‰¾åˆ° {sym} å¯¹åº”çš„ K çº¿æ–‡ä»¶ï¼Œå·²è·³è¿‡ã€‚")
                return sym, None, None
            df = load_ohlcv_flexible(str(sym2k[key]))
            out_csv = out_dir_p / f"{key}_events_labeled.csv"
            return run_one_symbol(key, df, sub, out_csv, H_bars, H_time, fee_pct, tie, entry_price_policy, nearest_tol)

        if jobs and jobs > 1:
            with ThreadPoolExecutor(max_workers=jobs) as ex:
                futs = {ex.submit(_task, s, g.copy()): str(s) for s, g in groups}
                for fut in as_completed(futs):
                    sym = futs[fut]
                    s, df_out, err = fut.result()
                    if err:
                        print(f"âŒ {sym}: {err}")
                    elif df_out is not None:
                        results.append(df_out)
        else:
            for s, g in groups:
                sym, df_out, err = _task(s, g.copy())
                if err:
                    print(f"âŒ {sym}: {err}")
                elif df_out is not None:
                    results.append(df_out)
    else:
        # é€æ–‡ä»¶å¤„ç†
        def _task_file(ewb_fp: Path):
            # æ ¹æ® events æ–‡ä»¶åæ¨æ–­ symbol
            sym = _extract_sym_from_name(ewb_fp, regex)
            key = str(sym).lower()
            if key not in sym2k:
                print(f"âš ï¸ æ²¡æ‰¾åˆ° {sym} å¯¹åº”çš„ K çº¿æ–‡ä»¶ï¼Œå·²è·³è¿‡ã€‚")
                return sym, None, None
            df = load_ohlcv_flexible(str(sym2k[key]))
            ev = pd.read_csv(ewb_fp)
            # é˜²æ­¢æ—¶é—´åˆ—ç±»å‹ä¸ä¸€
            for col in ["t_entry","entry_time","signal_time"]:
                if col in ev.columns:
                    ev[col] = pd.to_datetime(ev[col], utc=True, errors="coerce")
            out_csv = out_dir_p / f"{key}_events_labeled.csv"
            return run_one_symbol(key, df, ev, out_csv, H_bars, H_time, fee_pct, tie, entry_price_policy, nearest_tol)

        if jobs and jobs > 1:
            with ThreadPoolExecutor(max_workers=jobs) as ex:
                futs = {ex.submit(_task_file, fp): fp for fp in ewb_list}
                for fut in as_completed(futs):
                    fp = futs[fut]
                    s, df_out, err = fut.result()
                    if err:
                        print(f"âŒ {fp.name}: {err}")
                    elif df_out is not None:
                        results.append(df_out)
        else:
            for fp in ewb_list:
                sym, df_out, err = _task_file(fp)
                if err:
                    print(f"âŒ {fp.name}: {err}")
                elif df_out is not None:
                    results.append(df_out)

    # åˆå¹¶è¾“å‡º
    if merge_all:
        merged = pd.concat(results, ignore_index=True) if results else pd.DataFrame()
        out_path = Path(merge_all)
        out_path.parent.mkdir(parents=True, exist_ok=True)
        merged.to_csv(out_path, index=False, encoding="utf-8-sig")
        print(f"ğŸ§© å·²åˆå¹¶å¯¼å‡º: {out_path}  æ€»æ¡æ•°: {len(merged)}")

# ====================== CLI ======================

def main():
    ap = argparse.ArgumentParser(description="æ‰¹é‡å¯¹å¸¦ barriers çš„äº‹ä»¶è¿›è¡Œ TP/SL/H æ‰“æ ‡ï¼ˆæ”¯æŒè¿‘é‚»æ—¶é—´åŒ¹é…ä¸å…¥åœºä»·ç­–ç•¥ï¼‰ã€‚")
    ap.add_argument("--ohlcv", required=True, help="K çº¿æ–‡ä»¶æˆ–ç›®å½•ï¼ˆ.parquet/.csvï¼‰")
    ap.add_argument("--ewb",   required=True, help="events_with_barriers æ–‡ä»¶æˆ–ç›®å½•ï¼ˆæ”¯æŒå•CSVæˆ–ç›®å½•ï¼‰")
    ap.add_argument("--out_dir", required=True, help="è¾“å‡ºç›®å½•")

    # H å‚æ•°ï¼šäºŒé€‰ä¸€
    ap.add_argument("--H_bars", type=int, default=None, help="å³è¾¹ç•Œå‘å‰çœ‹çš„ bar æ•°ã€‚ä¸ --H_time äºŒé€‰ä¸€")
    ap.add_argument("--H_time", type=str, default=None, help="å³è¾¹ç•Œå‘å‰çœ‹çš„æ—¶é—´è·¨åº¦ï¼Œå¦‚ '90min','2D' ç­‰ã€‚ä¸ --H_bars äºŒé€‰ä¸€")

    ap.add_argument("--fee", type=float, default=0.0005, help="å•è¾¹è´¹ç‡ï¼ˆå«æ»‘ç‚¹ï¼‰ï¼Œé»˜è®¤ 0.0005")
    ap.add_argument("--tie", choices=["sl_first","tp_first"], default="sl_first", help="åŒæ ¹åŒæ—¶å‘½ä¸­ TP/SL æ—¶çš„ä¼˜å…ˆçº§")

    ap.add_argument("--regex", type=str, default=None, help="ä»æ–‡ä»¶åæŠ½å– symbol çš„æ­£åˆ™ï¼›è‹¥åŒ…å«å‘½åç»„ (?P<sym>...) åˆ™ä¼˜å…ˆä½¿ç”¨")

    ap.add_argument("--jobs", type=int, default=1, help="å¹¶å‘çº¿ç¨‹æ•°")
    ap.add_argument("--merge_all", type=str, default=None, help="æŠŠæ‰€æœ‰æ ‡çš„ç»“æœåˆå¹¶è¾“å‡ºåˆ°è¯¥ CSV è·¯å¾„")

    # æ–°å¢ï¼šå…¥åœºä»·ç­–ç•¥ & æœ€è¿‘åŒ¹é…å®¹å·®
    ap.add_argument("--entry_price_policy", choices=["same_open","next_open"], default="next_open",
                    help="å½“äº‹ä»¶æœªç»™ entry_price æ—¶çš„å›é€€ç­–ç•¥ï¼šsame_open=åŒæ ¹å¼€ç›˜ï¼›next_open=åä¸€æ ¹å¼€ç›˜ï¼ˆé»˜è®¤ï¼‰ã€‚è‹¥ç¼º open åˆ—åˆ™å›é€€åˆ° closeã€‚")
    ap.add_argument("--nearest_tol", type=str, default=None,
                    help="æŠŠæ—¶é—´æˆ³æ˜ å°„åˆ°æœ€è¿‘ bar æ—¶å…è®¸çš„æœ€å¤§æ—¶é—´å·®ï¼ˆå¦‚ '5min'ã€'2H'ã€'3D'ï¼‰ã€‚ç¼ºçœä¸é™åˆ¶ã€‚")

    args = ap.parse_args()

    if (args.H_bars is None) == (args.H_time is None):
        raise SystemExit("éœ€åœ¨ --H_bars ä¸ --H_time ä¸­äºŒé€‰ä¸€ã€‚")

    nearest_tol = pd.to_timedelta(args.nearest_tol) if args.nearest_tol else None

    run_batch(args.ohlcv, args.ewb, args.out_dir,
              H_bars=args.H_bars, H_time=args.H_time, fee_pct=args.fee, tie=args.tie,
              regex=args.regex, jobs=args.jobs, merge_all=args.merge_all,
              entry_price_policy=args.entry_price_policy, nearest_tol=nearest_tol)

if __name__ == "__main__":
    main()
